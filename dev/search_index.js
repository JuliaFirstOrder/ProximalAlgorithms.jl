var documenterSearchIndex = {"docs":
[{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"EditURL = \"https://github.com/JuliaFirstOrder/ProximalAlgorithms.jl/blob/master/docs/src/custom_objectives.jl\"","category":"page"},{"location":"custom_objectives/#custom_terms","page":"Custom objective terms","title":"Custom objective terms","text":"","category":"section"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"ProximalAlgorithms relies on the first-order primitives implemented in ProximalOperators: while a rich library of function types is provided there, one may need to formulate problems using custom objective terms. When that is the case, one only needs to implement the right first-order primitive, nabla f or operatornameprox_gamma f or both, for algorithms to be able to work with f.","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"Defining the proximal mapping for a custom function type requires adding a method for prox!.","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"For computing gradients, ProximalAlgorithms provides a fallback definition for gradient!, relying on Zygote to use automatic differentiation. Therefore, you can provide any (differentiable) Julia function wherever gradients need to be taken, and everything will work out of the box.","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"If however one would like to provide their own gradient implementation (e.g. for efficiency reasons), they can simply implement a method for gradient!.","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"ProximalAlgorithms.prox!(y, f, x, gamma)\nProximalAlgorithms.gradient!(g, f, x)","category":"page"},{"location":"custom_objectives/#ProximalOperators.prox!-NTuple{4, Any}","page":"Custom objective terms","title":"ProximalOperators.prox!","text":"prox!(y, f, x, gamma)\n\nCompute the proximal mapping of f at x, with stepsize gamma, and store the result in y. Return the value of f at y.\n\n\n\n\n\n","category":"method"},{"location":"custom_objectives/#ProximalOperators.gradient!-Tuple{Any, Any, Any}","page":"Custom objective terms","title":"ProximalOperators.gradient!","text":"gradient!(g, f, x)\n\nCompute the gradient of f at x, and stores it in y. Return the value of f at x.\n\n\n\n\n\n","category":"method"},{"location":"custom_objectives/#Example:-constrained-Rosenbrock","page":"Custom objective terms","title":"Example: constrained Rosenbrock","text":"","category":"section"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"Let's try to minimize the celebrated Rosenbrock function, but constrained to the unit norm ball. The cost function is","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"rosenbrock2D(x) = 100 * (x[2] - x[1]^2)^2 + (1 - x[1])^2","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"To enforce the constraint, we define the indicator of the unit ball, together with its proximal mapping: this is simply projection onto the unit norm ball, so it is sufficient to normalize any given point that lies outside of the set.","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"using LinearAlgebra\nusing ProximalOperators\n\nstruct IndUnitBall <: ProximalOperators.ProximableFunction end\n\n(::IndUnitBall)(x) = norm(x) > 1 ? eltype(x)(Inf) : eltype(x)(0)\n\nfunction ProximalOperators.prox!(y, ::IndUnitBall, x, gamma)\n    if norm(x) > 1\n        y .= x ./ norm(x)\n    else\n        y .= x\n    end\n    return zero(eltype(x))\nend","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"We can now minimize the function, for which we will use PANOC, which is a Newton-type method:","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"using ProximalAlgorithms\n\npanoc = ProximalAlgorithms.PANOC()\nsolution, iterations = panoc(-ones(2), f=rosenbrock2D, g=IndUnitBall())","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"Plotting the solution against the cost function contour and constraint, gives an idea of its correctness.","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"using Gadfly\n\ncontour = layer(\n    z=(x,y) -> rosenbrock2D([x, y]), xmin=[-2], xmax=[2], ymin=[-2], ymax=[2],\n    Geom.contour(levels=vcat([1.0, 10.0], [100.0 + 200.0 * k for k in 0:30])),\n)\npoint = layer(x=[solution[1]], y=[solution[2]], Geom.point)\ncircle = layer(x=cos.(0:0.01:2*pi), y=sin.(0:0.01:2*pi), Geom.path)\nplot(contour, circle, point, Guide.xlabel(nothing), Guide.ylabel(nothing))","category":"page"},{"location":"custom_objectives/#Example:-counting-operations","page":"Custom objective terms","title":"Example: counting operations","text":"","category":"section"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"It is often interesting to measure how many operations (gradient- or prox-evaluation) an algorithm is taking. In fact, in algorithms involving backtracking or some other line-search logic, the iteration count may not be entirely representative of the amount of operations are being performed; or maybe some specific implementations require additional operations to be performed when checking stopping conditions. All of this makes it difficult to quantify the exact iteration complexity.","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"We can achieve this by wrapping functions in a dedicated Counting type:","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"mutable struct Counting{T} <: ProximalOperators.ProximableFunction\n    f::T\n    gradient_count::Int\n    prox_count::Int\nend\n\nCounting(f::T) where T = Counting{T}(f, 0, 0)","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"Now we only need to intercept any call to gradient! and prox! and increase counters there:","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"function ProximalOperators.gradient!(y, f::Counting, x)\n    f.gradient_count += 1\n    return ProximalOperators.gradient!(y, f.f, x)\nend\n\nfunction ProximalOperators.prox!(y, f::Counting, x, gamma)\n    f.prox_count += 1\n    return ProximalOperators.prox!(y, f.f, x, gamma)\nend","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"We can run again the previous example, this time wrapping the objective terms within Counting:","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"f = Counting(rosenbrock2D)\ng = Counting(IndUnitBall())\n\nsolution, iterations = panoc(-ones(2), f=f, g=g)","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"and check how many operations where actually performed:","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"println(f.gradient_count)\nprintln(g.prox_count)","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"","category":"page"},{"location":"custom_objectives/","page":"Custom objective terms","title":"Custom objective terms","text":"This page was generated using Literate.jl.","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"EditURL = \"https://github.com/JuliaFirstOrder/ProximalAlgorithms.jl/blob/master/docs/src/getting_started.jl\"","category":"page"},{"location":"getting_started/#Getting-started","page":"Getting started","title":"Getting started","text":"","category":"section"},{"location":"getting_started/#Installation","page":"Getting started","title":"Installation","text":"","category":"section"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"To install the package, hit ] in the Julia REPL to enter the package manager mode, then run","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"pkg> add ProximalAlgorithms","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"to get the latest stable version, or","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"pkg> add ProximalAlgorithms#master","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"the latest development version (master branch).","category":"page"},{"location":"getting_started/#Overview","page":"Getting started","title":"Overview","text":"","category":"section"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"The methods implemented in ProximalAlgorithms are commonly referred to as (you've guessed it) proximal algorithms, in that they rely on the proximal operator (or mapping) to deal with non-differentiable terms in the objective. Loosely speaking, the algorithms in this package can be used to solve problems of the form","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"operatorname*minimize_x sum_i=1^N f_i(x)","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"where N depends on the specific algorithm, together with specific assumptions on the terms f_i (like smoothness, convexity, strong convexity). The problem above is solved by iteratively accessing specific first order information on the terms f_i, like their gradient nabla f_i or their proximal mapping operatornameprox_f_i:","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"mathrmprox_gamma f_i(x) = argmin_z left f_i(z) + tfrac12gammaz-x^2 right","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"The literature on proximal operators and algorithms is vast: for an overview, one can refer to Neal Parikh (2014), Amir Beck (2017).","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"To evaluate these first-order primitives, ProximalAlgorithms does the following:","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"nabla f_i falls back to using automatic differentiation (as provided by Zygote).\noperatornameprox_f_i relies on the intereface of ProximalOperators.","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"Both of the above can be implemented for custom function types, as documented here.","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"note: Note\nEach of the implemented algorithms assumes a different structure of the objective to be optimized (e.g., a specific number N of terms), with specific assumptions (e.g., smoothness, convexity). Furthermore, multiple algorithms can often be applied to the same problem (possibly through appropriate reformulation) and are expected to perform differently; sometimes, even the same algorithm can be applied in multiple ways to the same problem, by grouping (splitting) the terms in different ways.Because of these reasons, ProximalAlgorithms does not offer a modeling language to automagically minimize any objective: rather, the user is expected to formulate their problem by providing the right objective terms to the algorithm of choice. Please refer to the this section of the manual for information on what terms can be provided and under which assumptions.","category":"page"},{"location":"getting_started/#box_qp","page":"Getting started","title":"Example: box constrained quadratic","text":"","category":"section"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"As a four-line example, consider the minimization of a 2D quadratic function subject to box constraints:","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"using LinearAlgebra\nusing ProximalOperators\nusing ProximalAlgorithms\n\nquadratic_cost(x) = dot([3.4 1.2; 1.2 89.1] * x, x) / 2 + dot([2.3, 99.9], x)\nbox_indicator = ProximalOperators.IndBox(-1, 1)\n\nffb = ProximalAlgorithms.FastForwardBackward(maxit=1000, tol=1e-5, verbose=true)\nsolution, iterations = ffb(zeros(2), f=quadratic_cost, g=box_indicator)","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"Here, we defined the cost function quadratic_cost, and the constraint indicator box_indicator. Then we set up the optimization algorithm as the fast forward-backward splitting method (fast proximal gradient), with options for the maximum number of iterations, termination tolerance, verbosity. Finally, running the algorithm requires an initial point and the objective terms.","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"We can verify the correctness of the solution by checking that the negative gradient is orthogonal to the constraints, pointing outwards:","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"-ProximalAlgorithms.gradient(quadratic_cost, solution)[1]","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"Or by plotting the solution against the cost function and constraint:","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"using Gadfly\n\ncontour = layer(\n    z=(x,y) -> quadratic_cost([x, y]), xmin=[-2], xmax=[2], ymin=[-2], ymax=[2],\n    Geom.contour(levels=[quadratic_cost(solution) + k * 12 for k in 0:100]),\n)\npoint = layer(x=[solution[1]], y=[solution[2]])\nbox = layer(x=[-1, -1, 1, 1, -1], y=[1, -1, -1, 1, 1], Geom.path)\nplot(contour, box, point, Guide.xlabel(nothing), Guide.ylabel(nothing))","category":"page"},{"location":"getting_started/#iterator_interface","page":"Getting started","title":"Iterator interface","text":"","category":"section"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"Under the hood, all algorithms are implemented as standard Julia iterators. Following the previous example, the FastForwardBackward algorithm internally uses a ForwardBackwardIteration iterator object. Each iterator outputs the complete iteration state: interacting directly with this object allows for more fine-grained inspection and control over the algorithm, for example to report the algorithm's progress in a custom way (cost decrease, or whatever other metric), or to interrupt the optimization based on a custom stopping criterion.","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"note: Note\nSince each algorithm iterator type has its own logic, it will also have its own dedicated state structure. Interacting with the state then requires being familiar with its structure, and with the nature of its attributes.","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"For example, the optimization can be customized as follows: here we print the value of the cost function every ten iterations, and stop on a custom condition on the fixed-point residual norm.","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"ffbiter = ProximalAlgorithms.FastForwardBackwardIteration(x0=zeros(2), f=quadratic_cost, g=box_indicator)\n\nfor (k, state) in enumerate(ffbiter)\n    if mod(k, 10) == 0\n        println(\"iteration #$k: $(state.f_x)\")\n    end\n    if norm(state.res) / state.gamma <= 1e-4\n        break\n    end\nend","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"warning: Warning\nTo save on allocations, most (if not all) algorithms re-use state objects when iterating, by updating the state in place instead of creating a new one. For this reason, one should notmutate the state object in any way, as this may corrupt the algorithm's logic,\ncollect the sequence of states, since this will result in an array of identical objects.","category":"page"},{"location":"getting_started/#sparse_linreg","page":"Getting started","title":"Example: sparse linear regression","text":"","category":"section"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"Let's look at a least squares regression problem with L1 regularization: we will use the \"diabetes dataset\" (see here), so let's start by loading the data.","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"using HTTP\n\nsplitlines(s) = split(s, \"\\n\")\nsplitfields(s) = split(s, \"\\t\")\nparsefloat64(s) = parse(Float64, s)\n\nfunction load_diabetes_dataset()\n    res = HTTP.request(\"GET\", \"https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\")\n    lines = res.body |> String |> strip |> splitlines\n    return hcat((line |> splitfields .|> parsefloat64 for line in lines[2:end])...)'\nend\n\ndata = load_diabetes_dataset()\n\ntraining_input = data[1:end-100, 1:end-1]\ntraining_label = data[1:end-100, end]\n\ntest_input = data[end-99:end, 1:end-1]\ntest_label = data[end-99:end, end]\n\nn_training, n_features = size(training_input)","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"Now we can set up the optimization problem we want to solve: we will minimize the mean squared error for a linear model, appropriately scaled so that the features in the training data are normally distributed (\"standardization\", this is known to help the optimization process).","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"After some simple manipulation, this standardized linear model can be implemented as follows:","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"using LinearAlgebra\nusing Statistics\n\ninput_loc = mean(training_input, dims=1) |> vec\ninput_scale = std(training_input, dims=1) |> vec\n\nlinear_model(wb, input) = input * wb[1:end-1] .+ wb[end]\n\nfunction standardized_linear_model(wb, input)\n    w_scaled = wb[1:end-1] ./ input_scale\n    wb_scaled = vcat(w_scaled, wb[end] - dot(w_scaled, input_loc))\n    return linear_model(wb_scaled, input)\nend","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"The loss term in the cost is then the following. Note that this is a regular Julia function: since the algorithm we will apply requires its gradient, automatic differentiation will do the work for us.","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"mean_squared_error(label, output) = mean((output .- label) .^ 2) / 2\n\ntraining_loss(wb) = mean_squared_error(training_label, standardized_linear_model(wb, training_input))","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"As regularization we will use the L1 norm, implemented in ProximalOperators:","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"using ProximalOperators\n\nreg = ProximalOperators.NormL1(1)","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"We want to minimize the sum of training_loss and reg, and for this task we can use the fast proximal gradient method, also known as fast forward-backward splitting, or FISTA. Therefore we construct the algorithm, then apply it to our problem by providing a starting point, and the objective terms f=training_loss (smooth) and g=reg (non smooth).","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"using ProximalAlgorithms\n\nffb = ProximalAlgorithms.FastForwardBackward()\nsolution, iterations = ffb(zeros(n_features + 1), f=training_loss, g=reg)","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"We can now check how well the trained model performs on the test portion of our data.","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"test_output = standardized_linear_model(solution, test_input)\nmean_squared_error(test_label, test_output)","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"","category":"page"},{"location":"getting_started/","page":"Getting started","title":"Getting started","text":"This page was generated using Literate.jl.","category":"page"},{"location":"implemented_algorithms/#problems_algorithms","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"","category":"section"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"warning: Warning\nThis page is under construction, and may be incomplete.","category":"page"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"Depending on the structure a problem can be reduced to, different types of algorithms will apply. The major distinctions are in the number of objective terms, whether any of them is differentiable, whether they are composed with some linear mapping (which in general complicates evaluating the proximal mapping).","category":"page"},{"location":"implemented_algorithms/#two_terms_splitting","page":"Problem types and algorithms","title":"Two-terms: f + g","text":"","category":"section"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"This is the most popular model, by far the most thoroughly studied, and an abundance of algorithms exist to solve problems in this form.","category":"page"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"Algorithm Assumptions Oracle Implementation References\nForward-backward f smooth nabla f, operatornameprox_gamma g ForwardBackwardIteration Pierre-Louis Lions, Bertrand Mercier (1979)\nDouglas-Rachford  operatornameprox_gamma f, operatornameprox_gamma g DouglasRachfordIteration Jonathan Eckstein, Dimitri P Bertsekas (1992)\nFast forward-backward f convex, smooth, g convex nabla f, operatornameprox_gamma g FastForwardBackwardIteration Paul Tseng (2008), Amir Beck, Marc Teboulle (2009)\nPANOC f smooth nabla f, operatornameprox_gamma g PANOCIteration Lorenzo Stella, Andreas Themelis, Pantelis Sopasakis, Panagiotis Patrinos (2017)\nZeroFPR f smooth nabla f, operatornameprox_gamma g ZeroFPRIteration Andreas Themelis, Lorenzo Stella, Panagiotis Patrinos (2018)\nDouglas-Rachford line-search f smooth operatornameprox_gamma f, operatornameprox_gamma g DRLSIteration Andreas Themelis, Lorenzo Stella, Panagiotis Patrinos (2020)\nPANOC+ f locally smooth nabla f, operatornameprox_gamma g PANOCplusIteration Alberto De Marchi, Andreas Themelis (2021)","category":"page"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"ProximalAlgorithms.ForwardBackwardIteration\nProximalAlgorithms.DouglasRachfordIteration\nProximalAlgorithms.FastForwardBackwardIteration\nProximalAlgorithms.PANOCIteration\nProximalAlgorithms.ZeroFPRIteration\nProximalAlgorithms.DRLSIteration\nProximalAlgorithms.PANOCplusIteration","category":"page"},{"location":"implemented_algorithms/#ProximalAlgorithms.ForwardBackwardIteration","page":"Problem types and algorithms","title":"ProximalAlgorithms.ForwardBackwardIteration","text":"ForwardBackwardIteration(; <keyword-arguments>)\n\nInstantiate the forward-backward splitting algorithm (see [1]) for solving optimization problems of the form\n\nminimize f(x) + g(x),\n\nwhere f is smooth.\n\nArguments\n\nx0: initial point.\nf=Zero(): smooth objective term.\ng=Zero(): proximable objective term.\nLf=nothing: Lipschitz constant of the gradient of f.\ngamma=nothing: stepsize to use, defaults to 1/Lf if not set (but Lf is).\nadaptive=false: forces the method stepsize to be adaptively adjusted.\nminimum_gamma=1e-7: lower bound to gamma in case adaptive == true.\n\nReferences\n\nLions, Mercier, “Splitting algorithms for the sum of two nonlinear operators,” SIAM Journal on Numerical Analysis, vol. 16, pp. 964–979 (1979).\n\n\n\n\n\n","category":"type"},{"location":"implemented_algorithms/#ProximalAlgorithms.DouglasRachfordIteration","page":"Problem types and algorithms","title":"ProximalAlgorithms.DouglasRachfordIteration","text":"DouglasRachfordIteration(; <keyword-arguments>)\n\nInstantiate the Douglas-Rachford splitting algorithm (see [1]) for solving convex optimization problems of the form\n\nminimize f(x) + g(x).\n\nArguments\n\nx0: initial point.\nf=Zero(): proximable objective term.\ng=Zero(): proximable objective term.\ngamma: stepsize to use.\n\nReferences\n\nEckstein, Bertsekas, \"On the Douglas-Rachford Splitting Method and the Proximal Point Algorithm for Maximal Monotone Operators\", Mathematical Programming, vol. 55, no. 1, pp. 293-318 (1989).\n\n\n\n\n\n","category":"type"},{"location":"implemented_algorithms/#ProximalAlgorithms.FastForwardBackwardIteration","page":"Problem types and algorithms","title":"ProximalAlgorithms.FastForwardBackwardIteration","text":"FastForwardBackwardIteration(; <keyword-arguments>)\n\nInstantiate the accelerated forward-backward splitting algorithm (see [1, 2]) for solving optimization problems of the form\n\nminimize f(x) + g(x),\n\nwhere f is smooth.\n\nArguments\n\nx0: initial point.\nf=Zero(): smooth objective term.\ng=Zero(): proximable objective term.\nLf=nothing: Lipschitz constant of the gradient of f.\ngamma=nothing: stepsize to use, defaults to 1/Lf if not set (but Lf is).\nadaptive=false: forces the method stepsize to be adaptively adjusted.\nminimum_gamma=1e-7: lower bound to gamma in case adaptive == true.\n\nReferences\n\nTseng, \"On Accelerated Proximal Gradient Methods for Convex-Concave Optimization\" (2008).\nBeck, Teboulle, \"A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems\", SIAM Journal on Imaging Sciences, vol. 2, no. 1, pp. 183-202 (2009).\n\n\n\n\n\n","category":"type"},{"location":"implemented_algorithms/#ProximalAlgorithms.PANOCIteration","page":"Problem types and algorithms","title":"ProximalAlgorithms.PANOCIteration","text":"PANOCIteration(; <keyword-arguments>)\n\nInstantiate the PANOC algorithm (see [1]) for solving optimization problems of the form\n\nminimize f(Ax) + g(x),\n\nwhere f is smooth and A is a linear mapping (for example, a matrix).\n\nArguments\n\nx0: initial point.\nf=Zero(): smooth objective term.\nA=I: linear operator (e.g. a matrix).\ng=Zero(): proximable objective term.\nLf=nothing: Lipschitz constant of the gradient of x ↦ f(Ax).\ngamma=nothing: stepsize to use, defaults to 1/Lf if not set (but Lf is).\nadaptive=false: forces the method stepsize to be adaptively adjusted.\nminimum_gamma=1e-7: lower bound to gamma in case adaptive == true.\nmax_backtracks=20: maximum number of line-search backtracks.\ndirections=LBFGS(5): strategy to use to compute line-search directions.\n\nReferences\n\nStella, Themelis, Sopasakis, Patrinos, \"A simple and efficient algorithm for nonlinear model predictive control\", 56th IEEE Conference on Decision and Control (2017).\n\n\n\n\n\n","category":"type"},{"location":"implemented_algorithms/#ProximalAlgorithms.ZeroFPRIteration","page":"Problem types and algorithms","title":"ProximalAlgorithms.ZeroFPRIteration","text":"ZeroFPRIteration(; <keyword-arguments>)\n\nInstantiate the ZeroFPR algorithm (see [1]) for solving optimization problems of the form\n\nminimize f(Ax) + g(x),\n\nwhere f is smooth and A is a linear mapping (for example, a matrix).\n\nArguments\n\nx0: initial point.\nf=Zero(): smooth objective term.\nA=I: linear operator (e.g. a matrix).\ng=Zero(): proximable objective term.\nLf=nothing: Lipschitz constant of the gradient of x ↦ f(Ax).\ngamma=nothing: stepsize to use, defaults to 1/Lf if not set (but Lf is).\nadaptive=false: forces the method stepsize to be adaptively adjusted.\nminimum_gamma=1e-7: lower bound to gamma in case adaptive == true.\nmax_backtracks=20: maximum number of line-search backtracks.\ndirections=LBFGS(5): strategy to use to compute line-search directions.\n\nReferences\n\nThemelis, Stella, Patrinos, \"Forward-backward envelope for the sum of two nonconvex functions: Further properties and nonmonotone line-search algorithms\", SIAM Journal on Optimization, vol. 28, no. 3, pp. 2274–2303 (2018).\n\n\n\n\n\n","category":"type"},{"location":"implemented_algorithms/#ProximalAlgorithms.DRLSIteration","page":"Problem types and algorithms","title":"ProximalAlgorithms.DRLSIteration","text":"DRLSIteration(; <keyword-arguments>)\n\nInstantiate the Douglas-Rachford line-search algorithm (see [1]) for solving optimization problems of the form\n\nminimize f(x) + g(x),\n\nwhere f is smooth.\n\nArguments\n\nx0: initial point.\nf=Zero(): smooth objective term.\ng=Zero(): proximable objective term.\nmuf=nothing: convexity modulus of f.\nLf=nothing: Lipschitz constant of the gradient of f.\ngamma: stepsize to use, chosen appropriately based on Lf and muf by defaults.\nmax_backtracks=20: maximum number of line-search backtracks.\ndirections=LBFGS(5): strategy to use to compute line-search directions.\n\nReferences\n\nThemelis, Stella, Patrinos, \"Douglas-Rachford splitting and ADMM for nonconvex optimization: Accelerated and Newton-type linesearch algorithms\", arXiv:2005.10230, 2020.\n\n\n\n\n\n","category":"type"},{"location":"implemented_algorithms/#ProximalAlgorithms.PANOCplusIteration","page":"Problem types and algorithms","title":"ProximalAlgorithms.PANOCplusIteration","text":"PANOCplusIteration(; <keyword-arguments>)\n\nInstantiate the PANOCplus algorithm (see [1]) for solving optimization problems of the form\n\nminimize f(Ax) + g(x),\n\nwhere f is locally smooth and A is a linear mapping (for example, a matrix).\n\nArguments\n\nx0: initial point.\nf=Zero(): smooth objective term.\nA=I: linear operator (e.g. a matrix).\ng=Zero(): proximable objective term.\nLf=nothing: Lipschitz constant of the gradient of x ↦ f(Ax).\ngamma=nothing: stepsize to use, defaults to 1/Lf if not set (but Lf is).\nadaptive=false: forces the method stepsize to be adaptively adjusted.\nminimum_gamma=1e-7: lower bound to gamma in case adaptive == true.\nmax_backtracks=20: maximum number of line-search backtracks.\ndirections=LBFGS(5): strategy to use to compute line-search directions.\n\nReferences\n\nDe Marchi, Themelis, \"Proximal gradient algorithms under local Lipschitz gradient continuity: a convergence and robustness analysis of PANOC\", arXiv:2112.13000 (2021).\n\n\n\n\n\n","category":"type"},{"location":"implemented_algorithms/#three_terms_splitting","page":"Problem types and algorithms","title":"Three-terms: f + g + h","text":"","category":"section"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"When more than one non-differentiable term is there in the objective, algorithms from the previous section do not in general apply out of the box, since operatornameprox_gamma (f + g) does not have a closed form unless in particular cases. Therefore, ad-hoc iteration schemese have been studied.","category":"page"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"Algorithm Assumptions Oracle Implementation References\nDavis-Yin f g convex, h convex and smooth operatornameprox_gamma f, operatornameprox_gamma g, nabla h DavisYinIteration Damek Davis, Wotao Yin (2017)","category":"page"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"ProximalAlgorithms.DavisYinIteration","category":"page"},{"location":"implemented_algorithms/#ProximalAlgorithms.DavisYinIteration","page":"Problem types and algorithms","title":"ProximalAlgorithms.DavisYinIteration","text":"DavisYinIteration(; <keyword-arguments>)\n\nInstantiate the Davis-Yin splitting algorithm (see [1]) for solving convex optimization problems of the form\n\nminimize f(x) + g(x) + h(x),\n\nwhere h is smooth.\n\nArguments\n\nx0: initial point.\nf=Zero(): proximable objective term.\ng=Zero(): proximable objective term.\nh=Zero(): smooth objective term.\nLh=nothing: Lipschitz constant of the gradient of h.\ngamma=nothing: stepsize to use, defaults to 1/Lh if not set (but Lh is).\n\nReferences\n\nDavis, Yin. \"A Three-Operator Splitting Scheme and its Optimization Applications\", Set-Valued and Variational Analysis, vol. 25, no. 4, pp. 829–858 (2017).\n\n\n\n\n\n","category":"type"},{"location":"implemented_algorithms/#primal_dual_splitting","page":"Problem types and algorithms","title":"Primal-dual: f + g + h circ L","text":"","category":"section"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"When a function h is composed with a linear operator L, the proximal operator of h circ L does not have a closed form in general. For this reason, specific algorithms by the name of \"primal-dual\" splitting schemes are often applied to this model.","category":"page"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"Algorithm Assumptions Oracle Implementation References\nVu-Condat f convex and smooth, g h convex, L linear operator nabla f, operatornameprox_gamma g, operatornameprox_gamma h, L, L^* VuCodatIteration Bằng Công Vũ (2013), Laurent Condat (2013)\nAFBA f convex and smooth, g h convex, L linear operator nabla f, operatornameprox_gamma g, operatornameprox_gamma h, L, L^* AFBAIteration Puya Latafat, Panagiotis Patrinos (2017)","category":"page"},{"location":"implemented_algorithms/","page":"Problem types and algorithms","title":"Problem types and algorithms","text":"ProximalAlgorithms.AFBAIteration\nProximalAlgorithms.VuCondatIteration","category":"page"},{"location":"implemented_algorithms/#ProximalAlgorithms.AFBAIteration","page":"Problem types and algorithms","title":"ProximalAlgorithms.AFBAIteration","text":"AFBAIteration(; <keyword-arguments>)\n\nInstantiate the asymmetric forward-backward-adjoint algorithm (AFBA, see [1]) for solving convex optimization problems of the form\n\nminimize f(x) + g(x) + (h □ l)(L x),\n\nwhere f is smooth, g and h are possibly nonsmooth and l is strongly convex. Symbol □ denotes the infimal convolution, and L is a linear mapping.\n\nPoints x0 and y0 are the initial primal and dual iterates, respectively. If unspecified, functions f, g, and h default to the identically zero function, l defaults to the indicator of the set {0}, and L defaults to the identity. Important keyword arguments, in case f and l are set, are the Lipschitz constants beta_f and beta_l (see below).\n\nThe iterator implements Algorithm 3 of [1] with constant stepsize (α_n=λ) for several prominant special cases:\n\nθ = 2          ==>   Corresponds to the Vu-Condat Algorithm [2,3].\nθ = 1, μ=1\nθ = 0, μ=1\nθ ∈ [0,∞), μ=0\n\nSee [2, Section 5.2] and [1, Figure 1] for stepsize conditions, special cases, and relation to other algorithms.\n\nArguments\n\nx0: initial primal point.\ny0: initial dual point.\nf=Zero(): smooth objective term.\ng=Zero(): proximable objective term.\nh=Zero(): proximable objective term.\nl=IndZero(): strongly convex function.\nL=I: linear operator (e.g. a matrix).\nbeta_f=0: Lipschitz constant of the gradient of f.\nbeta_l=0: Lipschitz constant of the gradient of l conjugate.\ntheta=1: nonnegative algorithm parameter.\nmu=1: algorithm parameter in the range [0,1].\ngamma1: primal stepsize (see [1] for the default choice).\ngamma2: dual stepsize (see [1] for the default choice).\n\nReferences\n\nLatafat, Patrinos, \"Asymmetric forward–backward–adjoint splitting for solving monotone inclusions involving three operators\", Computational Optimization and Applications, vol. 68, no. 1, pp. 57-93 (2017).\nLatafat, Patrinos, \"Primal-dual proximal algorithms for structured convex optimization : a unifying framework\", In Large-Scale and Distributed Optimization, Giselsson and Rantzer, Eds. Springer International Publishing, pp. 97–120 ( 2018).\nCondat, \"A primal–dual splitting method for convex optimization involving Lipschitzian, proximable and linear composite terms\", Journal of Optimization Theory and Applications, vol. 158, no. 2, pp 460-479 (2013).\nVũ, \"A splitting algorithm for dual monotone inclusions involving cocoercive operators\", Advances in Computational Mathematics, vol. 38, no. 3, pp. 667-681 (2013).\n\n\n\n\n\n","category":"type"},{"location":"implemented_algorithms/#ProximalAlgorithms.VuCondatIteration","page":"Problem types and algorithms","title":"ProximalAlgorithms.VuCondatIteration","text":"VuCondatIteration(; <keyword-arguments>)\n\nInstantiate the Vũ-Condat primal-dual algorithm (see [1, 2]) for solving convex optimization problems of the form\n\nminimize f(x) + g(x) + (h □ l)(L x),\n\nwhere f is smooth, g and h are possibly nonsmooth and l is strongly convex. Symbol □ denotes the infimal convolution, and L is a linear mapping.\n\nFor the arguments see AFBAIteration.\n\nReferences\n\nCondat, \"A primal–dual splitting method for convex optimization involving Lipschitzian, proximable and linear composite terms\", Journal of Optimization Theory and Applications, vol. 158, no. 2, pp 460-479 (2013).\nVũ, \"A splitting algorithm for dual monotone inclusions involving cocoercive operators\", Advances in Computational Mathematics, vol. 38, no. 3, pp. 667-681 (2013).\n\n\n\n\n\n","category":"function"},{"location":"bibliography/#Bibliography","page":"Bibliography","title":"Bibliography","text":"","category":"section"},{"location":"bibliography/","page":"Bibliography","title":"Bibliography","text":"","category":"page"},{"location":"#ProximalAlgorithms.jl","page":"Home","title":"ProximalAlgorithms.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A Julia package for non-smooth optimization algorithms. Link to GitHub repository.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package provides algorithms for the minimization of objective functions that include non-smooth terms, such as constraints or non-differentiable penalties. Implemented algorithms include:","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Fast) Proximal gradient methods\nDouglas-Rachford splitting\nThree-term splitting\nPrimal-dual splitting algorithms\nNewton-type methods","category":"page"},{"location":"","page":"Home","title":"Home","text":"Check out this section for an overview of the available algorithms.","category":"page"},{"location":"#Citing","page":"Home","title":"Citing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use any of the algorithms from ProximalAlgorithms in your research, you are kindly asked to cite the relevant bibliography. Please check this section of the manual for algorithm-specific references.","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Contributions are welcome in the form of issue notifications or pull requests. When contributing new algorithms, we highly recommend looking at already implemented ones to get inspiration on how to structure the code.","category":"page"},{"location":"#Table-of-contents","page":"Home","title":"Table of contents","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"getting_started.md\",\n    \"implemented_algorithms.md\",\n    \"custom_objectives.md\",\n]\nDepth = 2","category":"page"}]
}
